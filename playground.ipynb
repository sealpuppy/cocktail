{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.utils.data as data\n",
    "import torch.nn.init as init\n",
    "import pytorch_ssim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import gc\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 5\n",
    "lr = 0.001\n",
    "mom = 0.9\n",
    "bs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def odd(w):\n",
    "    return list(np.arange(1, w, step=2, dtype='long'))\n",
    "\n",
    "def even(w):\n",
    "    return list(np.arange(0, w, step=2, dtype='long'))\n",
    "\n",
    "def white(x):\n",
    "    fw, tw = x.shape[1], x.shape[2]\n",
    "\n",
    "    first = F.relu(torch.normal(mean=torch.zeros(fw, tw), std=torch.ones(fw, tw)) ) * 0.05\n",
    "    second_seed = F.relu(torch.normal(mean=torch.zeros(fw//2, tw//2), std=torch.ones(fw//2, tw//2))) * 0.03\n",
    "    second = torch.zeros(fw, tw)\n",
    "\n",
    "    row_x  = torch.zeros(int(fw//2), tw)\n",
    "    # row_x = torch.zeros(int(fw/2), tw)\n",
    "\n",
    "    row_x[:, odd(tw)]  = second_seed\n",
    "    row_x[:, even(tw)] = second_seed\n",
    "\n",
    "    second[odd(fw), :]  = row_x\n",
    "    second[even(fw), :] = row_x\n",
    "\n",
    "    return second + first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=============================================\n",
    "#        path\n",
    "#=============================================\n",
    "\n",
    "server = False\n",
    "\n",
    "root_dir = '/home/tk/Documents/'\n",
    "if server == True:\n",
    "    root_dir = '/home/guotingyou/cocktail_phase2/'\n",
    "\n",
    "\n",
    "clean_dir = root_dir + 'clean/' \n",
    "# mix_dir = root_dir + 'mix/' \n",
    "# clean_label_dir = root_dir + 'clean_labels/' \n",
    "# mix_label_dir = root_dir + 'mix_labels/' \n",
    "\n",
    "cleanfolder = os.listdir(clean_dir)\n",
    "cleanfolder.sort()\n",
    "\n",
    "# mixfolder = os.listdir(mix_dir)\n",
    "# mixfolder.sort()\n",
    "\n",
    "\n",
    "clean_list = []\n",
    "# mix_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSourceDataSet(Dataset):\n",
    "    \n",
    "    def __init__(self, clean_dir):\n",
    "        \n",
    "\n",
    "        # Overfitting single block\n",
    "        with open(clean_dir + 'clean11.json') as f:\n",
    "            clean_list.append(torch.Tensor(json.load(f)))\n",
    "\n",
    "            \n",
    "        cleanblock = torch.cat(clean_list, 0)\n",
    "#         mixblock = torch.cat(mix_list, 0)\n",
    "        self.spec = cleanblock\n",
    "                \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.spec.shape[0]\n",
    "\n",
    "                \n",
    "    def __getitem__(self, index): \n",
    "\n",
    "        spec = self.spec[index]\n",
    "        return spec\n",
    "    \n",
    "#=============================================\n",
    "#        Define Dataloader\n",
    "#=============================================\n",
    "\n",
    "trainset = MSourceDataSet(clean_dir)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(dataset = trainset,\n",
    "                                                batch_size = bs,\n",
    "                                                shuffle = True)\n",
    "#=============================================\n",
    "#        Define Dataloader\n",
    "#=============================================\n",
    "\n",
    "trainset = MSourceDataSet(clean_dir)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(dataset = trainset,\n",
    "                                                batch_size = bs,\n",
    "                                                shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tk/.local/lib/python3.6/site-packages/torch/serialization.py:400: UserWarning: Couldn't retrieve source code for container of type ResBlock. It won't be checked for correctness upon loading.\n",
      "  \"type \" + container_type.__name__ + \". It won't be checked \"\n",
      "/home/tk/.local/lib/python3.6/site-packages/torch/serialization.py:400: UserWarning: Couldn't retrieve source code for container of type ResTranspose. It won't be checked for correctness upon loading.\n",
      "  \"type \" + container_type.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResDAE(\n",
      "  (upward_net1): Sequential(\n",
      "    (0): ResBlock(\n",
      "      (conv1): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (1): ResBlock(\n",
      "      (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (2): ResBlock(\n",
      "      (conv1): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (3): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (upward_net2): Sequential(\n",
      "    (0): Conv2d(8, 8, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): ResBlock(\n",
      "      (conv1): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (3): ResBlock(\n",
      "      (conv1): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (4): ResBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (upward_net3): Sequential(\n",
      "    (0): Conv2d(16, 16, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): ResBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (3): ResBlock(\n",
      "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (4): ResBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (upward_net4): Sequential(\n",
      "    (0): Conv2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): ResBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (3): ResBlock(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (4): ResBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (upward_net5): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): ResBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (3): ResBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (4): ResBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (upward_net6): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): ResBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (3): ResBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (4): ResBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (upward_net7): Sequential(\n",
      "    (0): Conv2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): ResBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (3): ResBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (4): ResBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (downward_net7): Sequential(\n",
      "    (0): ResBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (1): ResBlock(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (2): ResBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (3): ResTranspose(\n",
      "      (deconv1): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (downward_net6): Sequential(\n",
      "    (0): ResBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (1): ResBlock(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (2): ResBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (3): ResTranspose(\n",
      "      (deconv1): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (uconv5): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (downward_net5): Sequential(\n",
      "    (0): ResBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (1): ResBlock(\n",
      "      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (2): ResBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (3): ResTranspose(\n",
      "      (deconv1): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (uconv4): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (downward_net4): Sequential(\n",
      "    (0): ResBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (1): ResBlock(\n",
      "      (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (2): ResBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (3): ResTranspose(\n",
      "      (deconv1): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (uconv3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (downward_net3): Sequential(\n",
      "    (0): ResBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (1): ResBlock(\n",
      "      (conv1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (2): ResBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (3): ResTranspose(\n",
      "      (deconv1): ConvTranspose2d(16, 16, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (uconv2): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (downward_net2): Sequential(\n",
      "    (0): ResBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (1): ResBlock(\n",
      "      (conv1): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (2): ResBlock(\n",
      "      (conv1): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (3): ResTranspose(\n",
      "      (deconv1): ConvTranspose2d(8, 8, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (downward_net1): Sequential(\n",
      "    (0): ResBlock(\n",
      "      (conv1): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (1): ResBlock(\n",
      "      (conv1): Conv2d(8, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (2): ResBlock(\n",
      "      (conv1): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (3): ResBlock(\n",
      "      (conv1): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (4): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#=============================================\n",
    "#        Model\n",
    "#=============================================\n",
    "\n",
    "''' ResBlock '''\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, channels_in, channels_out):\n",
    "        super(ResBlock, self).__init__()\n",
    "\n",
    "        self.channels_in = channels_in\n",
    "        self.channels_out = channels_out\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=channels_in, out_channels=channels_out, kernel_size=(3,3), padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=channels_out, out_channels=channels_out, kernel_size=(3,3), padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.channels_out > self.channels_in:\n",
    "            x1 = F.relu(self.conv1(x), inplace = True)\n",
    "            x1 =        self.conv2(x1)\n",
    "            x  = self.sizematch(self.channels_in, self.channels_out, x)\n",
    "            return F.relu(x + x1, inplace = True)\n",
    "        elif self.channels_out < self.channels_in:\n",
    "            x = F.relu(self.conv1(x))\n",
    "            x1 =       self.conv2(x)\n",
    "            x = x + x1\n",
    "            return F.relu(x, inplace = True)\n",
    "        else:\n",
    "            x1 = F.relu(self.conv1(x), inplace = True)\n",
    "            x1 =        self.conv2(x1)\n",
    "            x = x + x1\n",
    "            return F.relu(x, inplace = True)\n",
    "\n",
    "    def sizematch(self, channels_in, channels_out, x):\n",
    "        zeros = torch.zeros( (x.size()[0], channels_out - channels_in, x.shape[2], x.shape[3]), dtype = torch.float32)\n",
    "        return torch.cat((x, zeros), dim=1)\n",
    "\n",
    "class ResTranspose(nn.Module):\n",
    "    def __init__(self, channels_in, channels_out):\n",
    "        super(ResTranspose, self).__init__()\n",
    "\n",
    "        self.channels_in = channels_in\n",
    "        self.channels_out = channels_out\n",
    "\n",
    "        self.deconv1 = nn.ConvTranspose2d(in_channels=channels_in, out_channels=channels_out, kernel_size=(2,2), stride=2)\n",
    "        self.deconv2 = nn.Conv2d(in_channels=channels_out, out_channels=channels_out, kernel_size=(3,3), padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # cin = cout\n",
    "        x1 = F.relu(self.deconv1(x), inplace = True)\n",
    "        x1 =        self.deconv2(x1)\n",
    "        x = self.sizematch(x)\n",
    "        return F.relu(x + x1, inplace = True)\n",
    "\n",
    "    def sizematch(self, x):\n",
    "        # expand\n",
    "        x2 = torch.zeros(x.shape[0], self.channels_in, x.shape[2]*2, x.shape[3]*2)\n",
    "\n",
    "        row_x  = torch.zeros(x.shape[0], self.channels_in, x.shape[2], 2*x.shape[3])\n",
    "        row_x[:,:,:,odd(x.shape[3]*2)]   = x\n",
    "        row_x[:,:,:,even(x.shape[3]*2)]  = x\n",
    "        x2[:,:, odd(x.shape[2]*2),:] = row_x\n",
    "        x2[:,:,even(x.shape[2]*2),:] = row_x\n",
    "\n",
    "        return x2\n",
    "\n",
    "\n",
    "def initialize(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        init.xavier_normal_(m.weight)\n",
    "        init.constant_(m.bias, 0)\n",
    "    if isinstance(m, nn.ConvTranspose2d):\n",
    "        init.xavier_normal_(m.weight)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model = ResDAE()\n",
    "model = torch.load(root_dir + 'recover/SSIM-CONV/DAE_SSIM.pkl')\n",
    "print (model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pytorch_ssim' has no attribute 'SSIM'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-b190c99bfbe6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#import pytorch_ssim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpytorch_ssim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSIM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#, momentum = mom)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pytorch_ssim' has no attribute 'SSIM'"
     ]
    }
   ],
   "source": [
    "\n",
    "#=============================================\n",
    "#        Optimizer\n",
    "#=============================================\n",
    "\n",
    "#import pytorch_ssim\n",
    "criterion = pytorch_ssim.SSIM()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr) #, momentum = mom)\n",
    "\n",
    "#=============================================\n",
    "#        Loss Record\n",
    "#=============================================\n",
    "\n",
    "loss_record = []\n",
    "# every_loss = []\n",
    "# epoch_loss = []\n",
    "\n",
    "#=============================================\n",
    "#        test\n",
    "#=============================================\n",
    "\n",
    "criterion = pytorch_ssim.SSIM()\n",
    "\n",
    "model.eval()\n",
    "for epo in range(epoch):\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs = data\n",
    "        inputs = Variable(inputs)\n",
    "        top = model.upward(inputs + white(inputs))\n",
    "        \n",
    "        outputs = model.downward(top, shortcut = True)\n",
    "        inputs = inputs.view(bs, 1, 256, 128)\n",
    "        outputs = outputs.view(bs, 1, 256, 128)\n",
    "        #with open ( root_dir + 'recover/L1loss_FC/recover_pic_epo_' + str(epo), 'w') as f:\n",
    "        #    json.dump(outputs.tolist(), f)\n",
    "        \n",
    "        loss = - criterion(outputs, inputs)\n",
    "        ssim_value = - loss.data.item()\n",
    "        \n",
    "        if i % 20 == 0:\n",
    "            inn = inputs[0].view(256, 128).detach().numpy() * 255\n",
    "            cv2.imwrite(\"/home/tk/Documents/recover/SSIM-CONV/test/\" + str(epo) + \"_\" + str(i) + \".png\", inn)\n",
    "            \n",
    "            out = outputs[0].view(256, 128).detach().numpy() * 255\n",
    "            cv2.imwrite(\"/home/tk/Documents/recover/SSIM-CONV/test/\" + str(epo) + \"_\" + str(i) + \"_re.png\", out)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "#=============================================\n",
    "#        Hyperparameters\n",
    "#=============================================\n",
    "\n",
    "epoch = 2\n",
    "lr = 0.001\n",
    "mom = 0.9\n",
    "bs = 16\n",
    "\n",
    "#======================================\n",
    "clean_dir = '/home/tk/Documents/clean/' \n",
    "clean_label_dir = '/home/tk/Documents/clean_labels/' \n",
    "#========================================\n",
    "\n",
    "cleanfolder = os.listdir(clean_dir)\n",
    "cleanfolder.sort()\n",
    "\n",
    "cleanlabelfolder = os.listdir(clean_label_dir)\n",
    "cleanlabelfolder.sort()\n",
    "\n",
    "clean_list = []\n",
    "clean_label_list = []\n",
    "\n",
    "#========================================\n",
    "\n",
    "class featureDataSet(Dataset):\n",
    "    \n",
    "    def __init__(self, clean_dir, clean_label_dir):\n",
    "                \n",
    "\n",
    "        for i in cleanfolder:\n",
    "            with open(clean_dir + '{}'.format(i)) as f:\n",
    "                clean_list.append(torch.Tensor(json.load(f)))\n",
    "                \n",
    "        for i in cleanlabelfolder:\n",
    "            with open(clean_label_dir + '{}'.format(i)) as f:\n",
    "                clean_label_list.append(torch.Tensor(json.load(f)))\n",
    "        \n",
    "        cleanblock = torch.cat(clean_list, 0)\n",
    "        self.spec = torch.cat([cleanblock], 0)\n",
    "                \n",
    "        cleanlabel = torch.cat(clean_label_list, 0)\n",
    "        self.label = torch.cat([cleanlabel], 0)\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.spec.shape[0]\n",
    "\n",
    "                \n",
    "    def __getitem__(self, index): \n",
    "\n",
    "        spec = self.spec[index]\n",
    "        label = self.label[index]\n",
    "        return spec, label\n",
    "\n",
    "    \n",
    "#=================================================    \n",
    "#           Dataloader \n",
    "#=================================================\n",
    "featureset = featureDataSet(clean_dir, clean_label_dir)\n",
    "trainloader = torch.utils.data.DataLoader(dataset = featureset,\n",
    "                                                batch_size = bs,\n",
    "                                                shuffle = True)\n",
    "\n",
    "#=================================================    \n",
    "#           model \n",
    "#=================================================\n",
    "class featureNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(featureNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(256 * 128, 500)\n",
    "        self.fc2 = nn.Linear(500, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 256*128)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "#model = featureNet()\n",
    "model = torch.load('/home/tk/Documents/FeatureNet.pkl')\n",
    "print (model)\n",
    "\n",
    "#============================================\n",
    "#              optimizer\n",
    "#============================================\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = lr, momentum = mom)\n",
    "\n",
    "#============================================\n",
    "#              training\n",
    "#============================================\n",
    "\n",
    "loss_record = []\n",
    "every_loss = []\n",
    "epoch_loss = []\n",
    "\n",
    "\n",
    "model.train()\n",
    "for epoch in range(70):\n",
    "    \n",
    "    \n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        \n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_record.append(loss.item())\n",
    "        every_loss.append(loss.item())\n",
    "        print ('[%d, %5d] loss: %.3f' % (epoch, i, loss.item()))\n",
    "        \n",
    "    epoch_loss.append(np.mean(every_loss))\n",
    "    every_loss = []\n",
    "\n",
    "            \n",
    "            \n",
    "torch.save(model, '/home/tk/Documents/FeatureNet.pkl')\n",
    "\n",
    "\n",
    "plt.figure(figsize = (20, 10))\n",
    "plt.plot(loss_record)\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig('loss.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (20, 10))\n",
    "plt.plot(epoch_loss)\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('epoch_loss')\n",
    "plt.savefig('epoch_loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featureNet(\n",
      "  (fc1): Linear(in_features=32768, out_features=500, bias=True)\n",
      "  (fc2): Linear(in_features=500, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tk/.local/lib/python3.6/site-packages/torch/serialization.py:400: UserWarning: Couldn't retrieve source code for container of type featureNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + container_type.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('/home/tk/Documents/FeatureNet.pkl')\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
