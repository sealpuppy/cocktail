{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 1\n",
    "lr = 0.0001\n",
    "mom = 0.005\n",
    "bs = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dir = '/home/guotingyou/cocktail_phase2/cocktail/clean/' \n",
    "mix_dir = '/Users/Terry/Documents/Research/test_block/' \n",
    "clean_label_dir = '/Users/Terry/Documents/Research/test_block/' \n",
    "mix_label_dir = '/Users/Terry/Documents/Research/test_block/' \n",
    "\n",
    "cleanfolder = os.listdir(clean_dir)\n",
    "cleanfolder.sort()\n",
    "\n",
    "# mixfolder = os.listdir(mix_dir)\n",
    "# mixfolder.sort()\n",
    "\n",
    "# cleanlabelfolder = os.listdir(clean_label_dir)\n",
    "# cleanlabelfolder.sort()\n",
    "\n",
    "# mixlabelfolder = os.listdir(mix_label_dir)\n",
    "# mixlabelfolder.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_list = []\n",
    "# mix_list = []\n",
    "# clean_label_list = []\n",
    "# mix_label_list = []\n",
    "\n",
    "\n",
    "class MSourceDataSet(Dataset):\n",
    "    \n",
    "    def __init__(self, clean_dir, mix_dir, clean_label_dir, mix_label_dir):\n",
    "        \n",
    "#        with open(clean_dir + 'clean0.json') as f:\n",
    "#            clean0 = torch.Tensor(json.load(f))\n",
    "        \n",
    "#         self.spec = clean0\n",
    "#         self.label = cleanlabel0\n",
    "            \n",
    "        \n",
    "        for i in cleanfolder:\n",
    "            with open(clean_dir + '{}'.format(i)) as f:\n",
    "                clean_list.append(torch.Tensor(json.load(f)))\n",
    "        \n",
    "#        for i in mixfolder:\n",
    "#             with open(mix_dir + '{}'.format(i)) as f:\n",
    "#                    mix_list.append(torch.Tensor(json.load(f)))\n",
    "                \n",
    "#         for i in cleanlabelfolder:\n",
    "#             with open(clean_label_dir + '{}'.format(i)) as f:\n",
    "#                 clean_label_list.append(torch.Tensor(json.load(f)))\n",
    "\n",
    "#         for i in mixlabelfolder:\n",
    "#             with open(mix_label_dir + '{}'.format(i)) as f:\n",
    "#                 mix_label_list.append(torch.Tensor(json.load(f)))\n",
    "        \n",
    "        cleanblock = torch.cat(clean_list, 0)\n",
    "#         mixblock = torch.cat(mix_list, 0)\n",
    "        self.spec = cleanblock\n",
    "                \n",
    "#         cleanlabel = torch.cat(clean_label_list, 0)\n",
    "#         mixlabel = torch.cat(mix_label_list, 0)\n",
    "#         self.label = torch.cat([cleanlabel, mixlabel], 0)\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.spec.shape[0]\n",
    "\n",
    "                \n",
    "    def __getitem__(self, index): \n",
    "\n",
    "        spec = self.spec[index]\n",
    "        return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = MSourceDataSet(clean_dir, mix_dir, clean_label_dir, mix_label_dir)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(dataset = trainset,\n",
    "                                                batch_size = 4,\n",
    "                                                shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "a = trainset.__len__()\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResDAE(\n",
      "  (upward_net1): Sequential(\n",
      "    (0): ResBlock(\n",
      "      (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (1): ResBlock(\n",
      "      (conv1): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (2): ResBlock(\n",
      "      (conv1): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (3): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (upward_net2): Sequential(\n",
      "    (0): Conv2d(8, 8, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): ResBlock(\n",
      "      (conv1): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (3): ResBlock(\n",
      "      (conv1): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (4): ResBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (upward_net3): Sequential(\n",
      "    (0): Conv2d(16, 16, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): ResBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (3): ResBlock(\n",
      "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (4): ResBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (upward_net4): Sequential(\n",
      "    (0): Conv2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): ResBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (3): ResBlock(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (4): ResBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (upward_net5): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): ResBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (3): ResBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (4): ResBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (upward_net6): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): ResBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (3): ResBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (4): ResBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (upward_net7): Sequential(\n",
      "    (0): Conv2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): ResBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (3): ResBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (4): ResBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (downward_net7): Sequential(\n",
      "    (0): ResBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (1): ResBlock(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (2): ResBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (3): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (downward_net6): Sequential(\n",
      "    (0): ResBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (1): ResBlock(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (2): ResBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (3): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (uconv5): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (downward_net5): Sequential(\n",
      "    (0): ResBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (1): ResBlock(\n",
      "      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (2): ResBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (3): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (uconv4): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (downward_net4): Sequential(\n",
      "    (0): ResBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (1): ResBlock(\n",
      "      (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (2): ResBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (3): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (uconv3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (downward_net3): Sequential(\n",
      "    (0): ResBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (1): ResBlock(\n",
      "      (conv1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (2): ResBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (3): ConvTranspose2d(16, 16, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (uconv2): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (downward_net2): Sequential(\n",
      "    (0): ResBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (1): ResBlock(\n",
      "      (conv1): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (2): ResBlock(\n",
      "      (conv1): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (3): ConvTranspose2d(8, 8, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (downward_net1): Sequential(\n",
      "    (0): ResBlock(\n",
      "      (conv1): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (1): ResBlock(\n",
      "      (conv1): Conv2d(8, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (2): ResBlock(\n",
      "      (conv1): Conv2d(4, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (3): ResBlock(\n",
      "      (conv1): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (4): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "''' ResBlock '''\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, channels_in, channels_out):\n",
    "        super(ResBlock, self).__init__()\n",
    "\n",
    "        self.channels_in = channels_in\n",
    "        self.channels_out = channels_out\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=channels_in, out_channels=channels_out, kernel_size=(3,3), padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=channels_out, out_channels=channels_out, kernel_size=(3,3), padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.channels_out > self.channels_in:\n",
    "            x1 = F.relu(self.conv1(x))\n",
    "            x1 =        self.conv2(x1)\n",
    "            x  = self.sizematch(self.channels_in, self.channels_out, x)\n",
    "            return x + x1\n",
    "        elif self.channels_out < self.channels_in:\n",
    "            x = F.relu(self.conv1(x))\n",
    "            x1 =       self.conv2(x)\n",
    "            x = x + x1\n",
    "            return x\n",
    "        else:\n",
    "            x1 = F.relu(self.conv1(x))\n",
    "            x1 =        self.conv2(x1)\n",
    "            x = x + x1\n",
    "            return x\n",
    "\n",
    "    def sizematch(self, channels_in, channels_out, x):\n",
    "        zeros = torch.zeros( (x.size()[0], channels_out - channels_in, x.shape[2], x.shape[3]), dtype = torch.float32)\n",
    "        return torch.cat((x, zeros), dim=1)\n",
    "\n",
    "class ResTranspose(nn.Module):\n",
    "    def __init__(self, channels_in, channels_out):\n",
    "        super(ResTranspose, self).__init__()\n",
    "\n",
    "        self.channels_in = channels_in\n",
    "        self.channels_out = channels_out\n",
    "\n",
    "        self.deconv1 = nn.ConvTranspose2d(in_channels=channels_in, out_channels=channels_out, kernel_size=(2,2), stride=2)\n",
    "        self.deconv2 = nn.Conv2d(in_channels=channels_out, out_channels=channels_out, kernel_size=(3,3), padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # cin = cout\n",
    "        x1 = F.relu(self.deconv1(x))\n",
    "        x1 =        self.deconv2(x1)\n",
    "        x = self.sizematch(x)\n",
    "        return x + x1\n",
    "\n",
    "    def sizematch(self, x):\n",
    "        # expand\n",
    "        x2 = torch.zeros(x.shape[0], self.channels_in, x.shape[2]*2, x.shape[3]*2)\n",
    "\n",
    "        row_x  = torch.zeros(x.shape[0], self.channels_in, x.shape[2], 2*x.shape[3])\n",
    "        row_x[:,:,:,odd(x.shape[3]*2)]   = x\n",
    "        row_x[:,:,:,even(x.shape[3]*2)]  = x\n",
    "        x2[:,:, odd(x.shape[2]*2),:] = row_x\n",
    "        x2[:,:,even(x.shape[2]*2),:] = row_x\n",
    "\n",
    "        return x2\n",
    "\n",
    "\n",
    "def initialize(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        init.xavier_normal_(m.weight)\n",
    "        init.constant_(m.bias, 0)\n",
    "    if isinstance(m, nn.ConvTranspose2d):\n",
    "        init.xavier_normal_(m.weight)\n",
    "\n",
    "\n",
    "\n",
    "class ResDAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResDAE, self).__init__()\n",
    "\n",
    "        # 128x128x1\n",
    "\n",
    "        self.upward_net1 = nn.Sequential(\n",
    "            ResBlock(1, 8),\n",
    "            ResBlock(8, 8),\n",
    "            ResBlock(8, 8),\n",
    "            nn.BatchNorm2d(8),\n",
    "        )\n",
    "\n",
    "        # 64x64x8\n",
    "\n",
    "        self.upward_net2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=8, out_channels=8, kernel_size=(2,2), stride=2),\n",
    "            nn.ReLU(),\n",
    "            ResBlock(8, 8),\n",
    "            ResBlock(8, 16),\n",
    "            ResBlock(16, 16),\n",
    "            nn.BatchNorm2d(16),\n",
    "        )\n",
    "\n",
    "        # 32x32x16\n",
    "\n",
    "        self.upward_net3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(2,2), stride=2),\n",
    "            nn.ReLU(),\n",
    "            ResBlock(16, 16),\n",
    "            ResBlock(16, 32),\n",
    "            ResBlock(32, 32),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "\n",
    "        # 16x16x32\n",
    "\n",
    "        self.upward_net4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(2,2), stride=2),\n",
    "            nn.ReLU(),\n",
    "            ResBlock(32, 32),\n",
    "            ResBlock(32, 64),\n",
    "            ResBlock(64, 64),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "\n",
    "        # 8x8x64\n",
    "\n",
    "        self.upward_net5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(2,2), stride=2),\n",
    "            nn.ReLU(),\n",
    "            ResBlock(64, 64),\n",
    "            ResBlock(64, 128),\n",
    "            ResBlock(128, 128),\n",
    "            nn.BatchNorm2d(128),\n",
    "        )\n",
    "\n",
    "        # 4x4x128\n",
    "\n",
    "        self.upward_net6 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(2,2), stride=2),\n",
    "            nn.ReLU(),\n",
    "            ResBlock(128, 128),\n",
    "            ResBlock(128, 256),\n",
    "            ResBlock(256, 256),\n",
    "            nn.BatchNorm2d(256),\n",
    "        )\n",
    "\n",
    "        # 2x2x256\n",
    "\n",
    "        self.upward_net7 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(2,2), stride=2),\n",
    "            nn.ReLU(),\n",
    "            ResBlock(256, 256),\n",
    "            ResBlock(256, 512),\n",
    "            ResBlock(512, 512),\n",
    "            nn.BatchNorm2d(512),\n",
    "        )\n",
    "\n",
    "        # 1x1x512\n",
    "        self.downward_net7 = nn.Sequential(\n",
    "            ResBlock(512, 512),\n",
    "            ResBlock(512, 256),\n",
    "            ResBlock(256, 256),\n",
    "            nn.ConvTranspose2d(256, 256, kernel_size = (2,2), stride = 2),\n",
    "            nn.BatchNorm2d(256),\n",
    "        )\n",
    "\n",
    "        # 2x2x256\n",
    "\n",
    "        self.downward_net6 = nn.Sequential(\n",
    "            # 8x8x64\n",
    "            ResBlock(256, 256),\n",
    "            ResBlock(256, 128),\n",
    "            ResBlock(128, 128),\n",
    "            nn.ConvTranspose2d(128, 128, kernel_size = (2,2), stride = 2),\n",
    "            nn.BatchNorm2d(128),\n",
    "        )\n",
    "\n",
    "        # 4x4x128\n",
    "        # cat -> 4x4x256\n",
    "        self.uconv5 = nn.Conv2d(256, 128, kernel_size=(3,3), padding=(1,1))\n",
    "        # 4x4x128\n",
    "        self.downward_net5 = nn.Sequential(\n",
    "            ResBlock(128, 128),\n",
    "            ResBlock(128, 64),\n",
    "            ResBlock(64, 64),\n",
    "            nn.ConvTranspose2d(64, 64, kernel_size = (2,2), stride = 2),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "\n",
    "        # 8x8x64\n",
    "        # cat -> 8x8x128\n",
    "        self.uconv4 = nn.Conv2d(128, 64, kernel_size=(3,3), padding=(1,1))\n",
    "        # 8x8x64\n",
    "        self.downward_net4 = nn.Sequential(\n",
    "            ResBlock(64, 64),\n",
    "            ResBlock(64, 32),\n",
    "            ResBlock(32, 32),\n",
    "            nn.ConvTranspose2d(32, 32, kernel_size = (2,2), stride = 2),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "\n",
    "        # 16x16x32\n",
    "        # cat -> 16x16x64\n",
    "        self.uconv3 = nn.Conv2d(64, 32, kernel_size=(3,3), padding=(1,1))\n",
    "        # 16x16x32\n",
    "        self.downward_net3 = nn.Sequential(\n",
    "            ResBlock(32, 32),\n",
    "            ResBlock(32, 16),\n",
    "            ResBlock(16, 16),\n",
    "            nn.ConvTranspose2d(16, 16, kernel_size = (2,2), stride = 2),\n",
    "            nn.BatchNorm2d(16),\n",
    "        )\n",
    "\n",
    "        # 32x32x16\n",
    "        # cat -> 32x32x32\n",
    "        self.uconv2 = nn.Conv2d(32, 16, kernel_size=(3,3), padding=(1,1))\n",
    "        # 32x32x16\n",
    "        self.downward_net2 = nn.Sequential(\n",
    "            ResBlock(16, 16),\n",
    "            ResBlock(16, 8),\n",
    "            ResBlock(8, 8),\n",
    "            nn.ConvTranspose2d(8, 8, kernel_size = (2,2), stride = 2),\n",
    "            nn.BatchNorm2d(8),\n",
    "        )\n",
    "\n",
    "        # 64x64x8\n",
    "        self.downward_net1 = nn.Sequential(\n",
    "            ResBlock(8, 8),\n",
    "            ResBlock(8, 4),\n",
    "            ResBlock(4, 1),\n",
    "            ResBlock(1, 1),\n",
    "#            nn.ConvTranspose2d(1, 1, kernel_size = (2,2), stride = 2),\n",
    "            nn.BatchNorm2d(1),\n",
    "        )\n",
    "\n",
    "        # 128x128x1\n",
    "\n",
    "\n",
    "    def upward(self, x, a7=None, a6=None, a5=None, a4=None, a3=None, a2=None):\n",
    "        x = x.view(bs, 1, 128, 128)\n",
    "        # 1x128x128\n",
    "#        print (\"initial\", x.shape)\n",
    "        x = self.upward_net1(x)\n",
    "#        print (\"after conv1\", x.shape)\n",
    "\n",
    "\n",
    "        # 8x64x64\n",
    "        x = self.upward_net2(x)\n",
    "        if a2 is not None: x = x * a2\n",
    "        self.x2 = x\n",
    "#        print (\"after conv2\", x.shape)\n",
    "\n",
    "        # 16x32x32\n",
    "        x = self.upward_net3(x)\n",
    "        if a3 is not None: x = x * a3\n",
    "        self.x3 = x\n",
    "#        print (\"after conv3\", x.shape)\n",
    "\n",
    "        # 32x16x16\n",
    "\n",
    "        x = self.upward_net4(x)\n",
    "        if a4 is not None: x = x * a4\n",
    "        self.x4 = x\n",
    "#        print (\"after conv4\", x.shape)\n",
    "\n",
    "        # 64x8x8\n",
    "\n",
    "        x = self.upward_net5(x)\n",
    "        if a5 is not None: x = x * a5\n",
    "        self.x5 = x\n",
    "#        print (\"after conv5\", x.shape)\n",
    "\n",
    "        \n",
    "        # 128x4x4\n",
    "        x = self.upward_net6(x)\n",
    "        if a6 is not None: x = x * a6\n",
    "#        print (\"after conv6\", x.shape)\n",
    "\n",
    "        # 256x2x2\n",
    "\n",
    "        x = self.upward_net7(x)\n",
    "        if a7 is not None: x = x * a7\n",
    "#        print (\"after conv7\", x.shape)\n",
    "\n",
    "        # 512x1x1\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "    def downward(self, y, shortcut= True):\n",
    "#        print (\"begin to downward, y.shape = \", y.shape)\n",
    "        # 512x1x1\n",
    "        y = self.downward_net7(y)\n",
    "#        print (\"after down7\", y.shape)\n",
    "\n",
    "\n",
    "        # 256x2x2\n",
    "        y = self.downward_net6(y)\n",
    "#        print (\"after down6\", y.shape)\n",
    "\n",
    "        # 128x4x4\n",
    "        if shortcut:\n",
    "            y = torch.cat((y, self.x5), 1)\n",
    "            y = F.relu(self.uconv5(y))\n",
    "        y = self.downward_net5(y)\n",
    "#        print (\"after down5\", y.shape)\n",
    "\n",
    "        # 64x8x8\n",
    "        if shortcut:\n",
    "            y = torch.cat((y, self.x4), 1)\n",
    "            y = F.relu(self.uconv4(y))\n",
    "        y = self.downward_net4(y)\n",
    "#        print (\"after down4\", y.shape)\n",
    "\n",
    "        # 32x16x16\n",
    "        if shortcut:\n",
    "            y = torch.cat((y, self.x3), 1)\n",
    "            y = F.relu(self.uconv3(y))\n",
    "        y = self.downward_net3(y)\n",
    "#        print (\"after down3\", y.shape)\n",
    "\n",
    "        # 16x32x32\n",
    "        if shortcut:\n",
    "            y = torch.cat((y, self.x2), 1)\n",
    "            y = F.relu(self.uconv2(y))\n",
    "        y = self.downward_net2(y)\n",
    "#        print (\"after down2\", y.shape)\n",
    "\n",
    "        # 8x64x64\n",
    "        y = self.downward_net1(y)\n",
    "#        print (\"after down1\", y.shape)\n",
    " \n",
    "        # 1x128x128\n",
    "\n",
    "        return y\n",
    "\n",
    "model = ResDAE()\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tk/anaconda3/lib/python3.7/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss(size_average = True)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = lr, momentum = mom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 這部分還沒加進去\n",
    "\n",
    "def odd(w):\n",
    "    return list(np.arange(1, w, step=2, dtype='long'))\n",
    "\n",
    "def even(w):\n",
    "    return list(np.arange(0, w, step=2, dtype='long'))\n",
    "\n",
    "def white(x):\n",
    "    fw, tw = x.shape[1], x.shape[2]\n",
    "\n",
    "    first = F.relu(torch.normal(mean=torch.zeros(fw, tw), std=torch.ones(fw, tw)) ) * 0.05\n",
    "    second_seed = F.relu(torch.normal(mean=torch.zeros(fw//2, tw//2), std=torch.ones(fw//2, tw//2))) * 0.03\n",
    "    second = torch.zeros(fw, tw)\n",
    "\n",
    "    row_x  = torch.zeros(int(fw//2), tw)\n",
    "    # row_x = torch.zeros(int(fw/2), tw)\n",
    "\n",
    "    row_x[:, odd(tw)]  = second_seed\n",
    "    row_x[:, even(tw)] = second_seed\n",
    "\n",
    "    second[odd(fw), :]  = row_x\n",
    "    second[even(fw), :] = row_x\n",
    "\n",
    "    return second + first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0,     0] loss: 154531888.000\n",
      "[0,    10] loss: 103379592.000\n",
      "[0,    20] loss: 77804320.000\n",
      "[0,    30] loss: 26700348.000\n",
      "[0,    40] loss: 153006144.000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-221-87d8c343054e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mtop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshortcut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-217-dabedc142ae7>\u001b[0m in \u001b[0;36mupward\u001b[0;34m(self, x, a7, a6, a5, a4, a3, a2)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;31m# 1x128x128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;31m#        print (\"initial\", x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupward_net1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;31m#        print (\"after conv1\", x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1621\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1622\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1623\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1624\u001b[0m     )\n\u001b[1;32m   1625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_record = []\n",
    "every_loss = []\n",
    "epoch_loss = []\n",
    "\n",
    "model.train()\n",
    "for epo in range(epoch):\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs = data\n",
    "        inputs = Variable(inputs)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        top = model.upward(inputs)\n",
    "        outputs = model.downward(top, shortcut = False)\n",
    "        \n",
    "        loss = criterion(inputs, outputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_record.append(loss.item())\n",
    "        every_loss.append(loss.item())\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print ('[%d, %5d] loss: %.3f' % (epo, i, loss.item()))\n",
    "        \n",
    "    epoch_loss.append(np.mean(every_loss))\n",
    "    every_loss = []\n",
    "\n",
    "torch.save(model, '/home/tk/Documents/DAE0.pkl')\n",
    "\n",
    "with open ('/home/tk/Documents/DAE_loss_record.json', 'w') as f:\n",
    "    json.dump(loss_record, f)\n",
    "    \n",
    "with open ('/home/tk/Documents/DAE_loss_epoch.json', 'w') as f:\n",
    "    json.dump(epoch_loss, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize = (20, 10))\n",
    "plt.plot(loss_record)\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig('DAE_loss.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize= (20, 10))\n",
    "plt.plot(epoch_loss)\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('epoch_loss')\n",
    "plt.savefig('DAE_epoch_loss.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
